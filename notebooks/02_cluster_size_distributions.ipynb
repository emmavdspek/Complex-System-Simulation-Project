{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cluster Size Distribution Analysis\n",
    "This notebook showcases the usage of the analysis functions in analysis.py regarding cluster size distributions. This will be shown both using directly simulated data, as well as loaded data from previously generated data.\n",
    "\n",
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import src.CA_model as CA\n",
    "import src.analysis as an\n",
    "import src.utils as ut\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### Reload our own modules in case they are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to reload CA_model.py, analysis.py and utils.py for updated code\n",
    "reload(CA)\n",
    "reload(an)\n",
    "reload(ut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Distribution of a single dataset\n",
    "The following cells show the process of generating the cluster size distribution of a single simulation. This data is generated directly for convenience, instead of saved and loaded first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings\n",
    "size = 100                          # width and height of the grid\n",
    "p = 0.5                             # starting fraction of vegetation\n",
    "update_rule = CA.update_Scanlon2007 # function containing update rule\n",
    "true_frac=0.2                       # 'natural' (equilibrium) fraction of vegetation\n",
    "k=3                                 # strength of local interactions\n",
    "M=10                                # radius of neighbourhood\n",
    "N_steps=200                         # number of iterations\n",
    "skip=0                              # iterations to skip (equilibration period)\n",
    "seed=0\n",
    "\n",
    "grids = CA.evolve_CA(\n",
    "    size=size,\n",
    "    p=p,\n",
    "    update_rule=update_rule,\n",
    "    true_frac=true_frac,\n",
    "    k=k,\n",
    "    M=M,\n",
    "    N_steps=N_steps,\n",
    "    skip=skip,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Fit results and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list, fit = an.cluster_sizes(grids)\n",
    "alpha = fit.truncated_power_law.alpha\n",
    "s_char = 1 / (fit.truncated_power_law.Lambda)\n",
    "R, p = fit.distribution_compare(\"truncated_power_law\", \"exponential\", normalized_ratio=True)\n",
    "\n",
    "print(\"Scaling exponent: \", alpha)\n",
    "print(\"Characteristic length: \", s_char)\n",
    "print(\"Loglikelihood ratio (if positive, (truncated) power law more likely than exponential): \", R)\n",
    "print(\"Significance value: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Plot of the data and fit with truncated power law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_cluster_size_distr(size_lists=[size_list], fits=[fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Average distribution of several datasets\n",
    "To showcase how data of different simulations (with different seeds, but the same set of parameters) can be combined into one set, which can then again be passed on to cluster_sizes(). The main idea is all grids of all simulations are combined into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100                          # width and height of the grid\n",
    "p = 0.5                             # starting fraction of vegetation\n",
    "update_rule = CA.update_Scanlon2007 # function containing update rule\n",
    "true_frac=0.2                       # 'natural' (equilibrium) fraction of vegetation\n",
    "k=3                                 # strength of local interactions\n",
    "M=10                                # radius of neighbourhood\n",
    "N_steps=200                         # number of iterations\n",
    "skip=100                            # iterations to skip (equilibration period)\n",
    "starting_seed=0\n",
    "\n",
    "N_evolutions = 5                    # number of full evolutions to generate for this set of parameters\n",
    "all_grids = []\n",
    "\n",
    "for i in range(N_evolutions):\n",
    "    start = time.time()\n",
    "    seed = starting_seed+i\n",
    "    grids = CA.evolve_CA(\n",
    "        size=size,\n",
    "        p=p,\n",
    "        update_rule=update_rule,\n",
    "        true_frac=true_frac,\n",
    "        k=k,\n",
    "        M=M,\n",
    "        N_steps=N_steps,\n",
    "        skip=skip,\n",
    "        seed=seed,\n",
    "    )\n",
    "    # grids = ut.load_data(size, update_rule, np.round(true_fracs[i],2), k, M, N_steps, skip, starting_seed+i)\n",
    "    all_grids.append(grids)\n",
    "    end = time.time()\n",
    "    print(f\"Grid evolution {i+1} out of {N_evolutions} completed in {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the list of lists into a 1D list of grids\n",
    "combined_grids = [grid for grid_list in all_grids for grid in grid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list, fit = an.cluster_sizes(combined_grids)\n",
    "alpha = fit.truncated_power_law.alpha\n",
    "s_char = 1 / (fit.truncated_power_law.Lambda)\n",
    "R, p = fit.distribution_compare(\"truncated_power_law\", \"exponential\", normalized_ratio=True)\n",
    "\n",
    "print(\"Scaling exponent: \", alpha)\n",
    "print(\"Characteristic length: \", s_char)\n",
    "print(\"Loglikelihood ratio (if positive, (truncated) power law more likely than exponential): \", R)\n",
    "print(\"Significance value: \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_cluster_size_distr(size_lists=[size_list], fits=[fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Several cluster size distributions in one plot\n",
    "In the previous cells, we plotted a single cluster size distribution in each plot. In the following we show how to plot many distributions together in a single plot, corresponding to different parameter settings. Since this quickly requires a lot of data, the following is based on loaded data instead of in-line generated data. For generating the required loaded data, see 00_data_management.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for which data should be analysed\n",
    "size = 500                          # width and height of the grid\n",
    "p = 0.5                             # starting fraction of vegetation\n",
    "update_rule = CA.update_Scanlon2007 # function containing update rule\n",
    "true_fracs=np.arange(0.05,0.7,0.05) # 'natural' (equilibrium) fraction of vegetation\n",
    "k=3                                 # strength of local interactions\n",
    "M=20                                # radius of neighbourhood\n",
    "N_steps=200                         # number of iterations\n",
    "skip=100                            # iterations to skip (equilibration period)\n",
    "starting_seed=0\n",
    "\n",
    "size_lists = []\n",
    "fits = []\n",
    "\n",
    "for i in range(len(true_fracs)):\n",
    "    loaded_grids = ut.load_data_wo_phi(size, update_rule, np.round(true_fracs[i],2), k, M, N_steps, skip, starting_seed+i)\n",
    "    # retrieve the cumulative cluster size distribution\n",
    "    size_list, fit = an.cluster_sizes(loaded_grids)\n",
    "    size_lists.append(size_list)\n",
    "    fits.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_cluster_size_distr(size_lists=size_lists, fits=fits, params=true_fracs, param_name=r\"$f^{*}$\")\n",
    "figname = f\"DISTR_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_seed={starting_seed}.pdf\"\n",
    "fig.savefig(\"../results/figures/\" + figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_alpha_vs_true_frac(fits=fits, true_fracs=true_fracs)\n",
    "figname = f\"ALPHA_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_seed={starting_seed}.pdf\"\n",
    "fig.savefig(\"../results/figures/\" + figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_all in [True, False]:\n",
    "    fig = an.plot_fit_statistics_vs_true_frac(fits=fits, true_fracs=true_fracs, plot_all=plot_all)\n",
    "    figname = f\"STATISTICS_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_seed={starting_seed}_{plot_all}.pdf\"\n",
    "    fig.savefig(\"../results/figures/\" + figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Average of several datasets for different sets of parameters\n",
    "As the icing on the cake, this is a combination of the previous part of the notebook. Here we are plotting different datasets in one plot, where each one is an average over several iterations. Again, the data is loaded from previously generated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for which data should be analysed\n",
    "size = 500                          # width and height of the grid\n",
    "p = 0.5                             # starting fraction of vegetation\n",
    "update_rule = CA.update_Scanlon2007 # function containing update rule\n",
    "true_fracs=np.arange(0.05,0.7,0.05) # 'natural' (equilibrium) fraction of vegetation\n",
    "# true_fracs=[0.45]\n",
    "k=3                                 # strength of local interactions\n",
    "M=20                                # radius of neighbourhood\n",
    "N_steps=200                         # number of iterations\n",
    "skip=100                            # iterations to skip (equilibration period)\n",
    "starting_seeds=[0,100,200]          # starting seeds used for the different iterations per set of parameters\n",
    "\n",
    "size_lists = []\n",
    "fits = []\n",
    "\n",
    "for i in range(len(true_fracs)):\n",
    "    all_grids = []\n",
    "    for starting_seed in starting_seeds:\n",
    "        loaded_grids = ut.load_data_wo_phi(size, update_rule, np.round(true_fracs[i],2), k, M, N_steps, skip, starting_seed+i)\n",
    "        all_grids.append(loaded_grids)\n",
    "    # flatten the list of lists into a 1D list of grids\n",
    "    combined_grids = [grid for grid_list in all_grids for grid in grid_list]\n",
    "\n",
    "    # retrieve the cumulative cluster size distribution\n",
    "    size_list, fit = an.cluster_sizes(combined_grids)\n",
    "    size_lists.append(size_list)\n",
    "    fits.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_cluster_size_distr(size_lists=size_lists, fits=fits, params=true_fracs, param_name=r\"$f^{*}$\")\n",
    "figname = f\"DISTR_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_Nseeds={len(starting_seeds)}.pdf\"\n",
    "fig.savefig(\"../results/figures/\" + figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = an.plot_alpha_vs_true_frac(fits=fits, true_fracs=true_fracs)\n",
    "figname = f\"ALPHA_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_Nseeds={len(starting_seeds)}.pdf\"\n",
    "fig.savefig(\"../results/figures/\" + figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_all in [True, False]:\n",
    "    fig = an.plot_fit_statistics_vs_true_frac(fits=fits, true_fracs=true_fracs, plot_all=plot_all)\n",
    "    figname = f\"STATISTICS_{update_rule.__name__}_size={size}_Nsteps={N_steps}_skip={skip}_truefrac={np.round(true_fracs[0],2)}to{np.round(true_fracs[-1],2)}_k={k}_M={M}_Nseeds={len(starting_seeds)}_{plot_all}.pdf\"\n",
    "    fig.savefig(\"../results/figures/\" + figname, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "base"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    },
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 5,
           "op": "addrange",
           "valuelist": "5"
          },
          {
           "key": 5,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
